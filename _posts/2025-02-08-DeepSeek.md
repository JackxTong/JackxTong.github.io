---
layout:     post
title:      DeepSeek
subtitle:   Real time trading experience
date:       2025-02-08
author:     TX
header-img: img/Optiver.jpeg
catalog: true
label: notes
tags:
    - Deep learning
    - LLM
---


## V3-Base
671B decoder-only transformer
Self-supervised pre-training:
No label, train on first half of sentence to predict the second half

## R1-Zero

Trained on v3-base using reinforcement learning:
Supervised fine tuning (SFT)
Reinforcement Learning from Human Feedback (RLHF)

## R1

Use R1-zero to come up with good CoT
Use those CoT to fine-tune V3-Base
Then train with SFT to get R1

## Llama/Qwen Distilled

Use R1 to come up with 800k samples, then use those
to train other open-source models: Meta & Qwen

## Other techniques

MoE system
Multihead latent Attention (MLA)
Distilling using O1
Low-level programming GPU cores
Group Relative Policy Optimization (GRPO)