<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TX Blog</title>
    <description>Every failure is leading towards success.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 12 Feb 2025 16:01:26 +0000</pubDate>
    <lastBuildDate>Wed, 12 Feb 2025 16:01:26 +0000</lastBuildDate>
    <generator>Jekyll v4.3.4</generator>
    
      <item>
        <title>Some Quant Finance</title>
        <description>&lt;h1 id=&quot;what-are-options&quot;&gt;What are options?&lt;/h1&gt;
&lt;h2 id=&quot;greeks&quot;&gt;Greeks&lt;/h2&gt;
&lt;h3 id=&quot;delta&quot;&gt;Delta&lt;/h3&gt;
&lt;p&gt;0.5 for in the money
close to 0 for OTM
close to 1 for ITM&lt;/p&gt;

&lt;h3 id=&quot;gamma&quot;&gt;Gamma&lt;/h3&gt;
&lt;p&gt;High means convex trade (delta moves faster than underlying)
Highest for ATM
Close to 0 for OTM and ITM&lt;/p&gt;

&lt;h3 id=&quot;vega&quot;&gt;Vega&lt;/h3&gt;
&lt;p&gt;WRT Change in implied vol
Same for calls and puts&lt;/p&gt;

&lt;p&gt;Gamma and vega usually always positive&lt;/p&gt;

&lt;h3 id=&quot;volatility&quot;&gt;Volatility&lt;/h3&gt;
&lt;p&gt;Standard deviation of log return of some risky assets&lt;/p&gt;

&lt;h2 id=&quot;equity-options&quot;&gt;Equity Options&lt;/h2&gt;
&lt;h3 id=&quot;brownian-motion&quot;&gt;Brownian motion&lt;/h3&gt;

&lt;p&gt;1.B_0 = 0, for any  0,t1…,tn, increment Bt2 - Bt1, are independent&lt;br /&gt;
2.stationary &amp;amp; normal: Bt+h - Bt depend on h only, Bt+h - Bt ~ N(0, h)&lt;br /&gt;
3.Continuous path, B(t) cont over t&lt;/p&gt;

&lt;h3 id=&quot;filtrationsigma-algebera-ft&quot;&gt;filtration/sigma algebera Ft:&lt;/h3&gt;

&lt;p&gt;set of all events up to time t&lt;/p&gt;

&lt;h3 id=&quot;martingale&quot;&gt;Martingale&lt;/h3&gt;
&lt;p&gt;1.Xt is Ft measurable&lt;br /&gt;
2.E[Xt] is finite for all t&lt;br /&gt;
3.E[Xt|Fs] = Xs (expecation of future given past information is current value)&lt;/p&gt;

&lt;p&gt;This suggests there is no systematic way to predict future changes and make a guaranteed profit.&lt;/p&gt;

&lt;h3 id=&quot;black-scholes&quot;&gt;Black-Scholes&lt;/h3&gt;

&lt;p&gt;Assumptions&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Efficient market (all past information already reflected in current stock price)&lt;/li&gt;
  &lt;li&gt;Stock price follows geometric brownian motion, or Log(St) is normal 
(i.e. St = S0 exp( (mu - sig^2/2)t + sig Wt) )&lt;/li&gt;
  &lt;li&gt;Volatility is assumed to be constant&lt;/li&gt;
  &lt;li&gt;Risk free rate constant and known&lt;/li&gt;
  &lt;li&gt;Arbitrage free&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;call-put-parity&quot;&gt;call-put parity&lt;/h3&gt;
&lt;p&gt;C - P = S - Ke^-rT&lt;/p&gt;

&lt;p&gt;If C is cheaper, can buy C sell P and also short the stock&lt;br /&gt;
hedged against price and profit from selling P&lt;/p&gt;

&lt;p&gt;Can also construct butterfly with the cheap C: Buy call at K1 and K3, short C at K2&lt;/p&gt;

&lt;h3 id=&quot;volatility-smile&quot;&gt;Volatility smile&lt;/h3&gt;

&lt;p&gt;implied volatility (IV) is higher for options that are deep in-the-money or out-of-the-money compared to at-the-money options.&lt;/p&gt;

&lt;p&gt;Cannot compute IV analytically, have to numerical (bisection or newton)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Input requirement: max(S0 - Ke^-rT, 0) &amp;lt; call price &amp;lt; stock price&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Why does it exist?
ITM and OTM options are more in demand than ATM options
Consumers buy in-the-money (K &amp;gt; S0e^rT) put as insurance for stock crash (payoff = K - ST)&lt;br /&gt;
ITM put and OTM call has intrinsic value&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fixed income products, how to price how to hedge&lt;/p&gt;

&lt;p&gt;What are swaps&lt;/p&gt;

&lt;h3 id=&quot;volatility-trading&quot;&gt;volatility trading&lt;/h3&gt;
&lt;p&gt;During periods of high volatility, price fluctuations are more frequent, creating more opportunities for market makers to capture the bid-ask spread.&lt;br /&gt;
At same time, higher risk too. To hedge, may need wider spread.&lt;br /&gt;
Less volatile times (more liquidity), can have tight spread, less risk of unfavorable move&lt;/p&gt;

&lt;p&gt;Trading gamma:&lt;br /&gt;
Positive gamma, or convex option: 
Stock up -&amp;gt; delta up -&amp;gt; option up even faster&lt;br /&gt;
During volatile times, option would be even more volatile, need to hedge more frequently&lt;br /&gt;
more opportunies for bid-ask spread, also can keep buying low and selling high&lt;/p&gt;

&lt;h3 id=&quot;options-futures-swaps&quot;&gt;options, futures, swaps&lt;/h3&gt;
&lt;p&gt;forward-similar to future, but OTC, cannot be priced
swaps - agreement to exchange cash flow, priced on net present value
futures - S0 * e^rT (no up-front payment)&lt;/p&gt;

&lt;h3 id=&quot;garch-for-volatility-forecast&quot;&gt;GARCH for volatility forecast&lt;/h3&gt;
&lt;p&gt;sig_t^2 = long_term_vol + a * eps_t-1^2 + b * sig_t-1^2&lt;/p&gt;

&lt;p&gt;long_term_vol: fixed constant&lt;br /&gt;
eps_t-1: residual derived from log return log(Rt/Rt-1) with mean removed&lt;br /&gt;
sig_t-1: previous volatility (can be implied volatility from Black-Scholes)&lt;/p&gt;

&lt;h2 id=&quot;fixed-income&quot;&gt;Fixed Income&lt;/h2&gt;
&lt;p&gt;interest rates often follow stochastic processes (e.g., Vasicek, CIR).&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Explain monte carlo
run large number of senarios to aggregate, useful when analytical solutions are difficult&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Explain VaR for a portfolio&lt;br /&gt;
VaR = Upper bound of Confidence interval for the loss&lt;br /&gt;
ES = E[ loss | loss &amp;gt; VaR]&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;VaR ignores tail risk. One can say 99% confident Loss won’t exceed 1M, but within the 1% chance, don’t know if it’s 1M or 1B. ES addresses this&lt;/p&gt;

&lt;p&gt;Also VAR is not subadditive: risk(A+B) &amp;lt; risk(A) + risk(B), which encourage diversification&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pricing interest rate swaps.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;forward-similar to future, but OTC, cannot be priced
swaps - agreement to exchange cash flow, priced on net present value
futures - S0 * e^rT (no up-front payment)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;How to hedge bond portfolio against interest rate risk using swaps&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What are the key risk factors in a fixed income portfolio?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;If 10-year Treasury yields rise by 20 bps, how would you expect corporate bond spreads to behave and why?&lt;/li&gt;
  &lt;li&gt;A zero-coupon bond matures in 5 years. How does its price sensitivity to interest rates compare to a 5-year coupon bond?&lt;/li&gt;
  &lt;li&gt;Bond portfolio sharpe ratio&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;fx&quot;&gt;Fx&lt;/h2&gt;

&lt;h2 id=&quot;pricing-options-with-monte-carlo&quot;&gt;Pricing options with Monte Carlo&lt;/h2&gt;
&lt;p&gt;Simulate payoff with Geometric brownian motion
Then option price = e^-rT * (average payoff)&lt;/p&gt;

&lt;p&gt;Used when Closed-form solutions are unavailable (e.g. multi-asset options)&lt;/p&gt;

&lt;p&gt;Converges at O(1/sqrt(N)), very slow and expensive&lt;/p&gt;

&lt;h2 id=&quot;risk-management&quot;&gt;Risk management&lt;/h2&gt;
&lt;p&gt;Can use PCA to find which risks contribute to portfolio’s risk&lt;/p&gt;

&lt;p&gt;Look for dimension of max variance, opposed to ICA which look for least entropy (least normal)&lt;/p&gt;

&lt;p&gt;Also find which factors drive asset returns (macro factors)&lt;/p&gt;

&lt;h3 id=&quot;inefficiency-vs-arbitrage-free&quot;&gt;Inefficiency vs Arbitrage-free&lt;/h3&gt;

&lt;p&gt;A market can be inefficient but not arbitrage-free.&lt;/p&gt;

&lt;p&gt;A stock may exhibit price momentum because markets fail to quickly incorporate information.&lt;/p&gt;

&lt;p&gt;Traders could exploit this pattern (inefficiency) by predicting future price movements, but this involves risk.&lt;/p&gt;

&lt;p&gt;At the same time, the market could be arbitrage-free because there are no riskless opportunities to exploit inconsistencies in pricing.&lt;/p&gt;

&lt;h3 id=&quot;itos-formula&quot;&gt;Ito’s formula&lt;/h3&gt;
&lt;p&gt;Given dX = mu dt + sig dW&lt;/p&gt;

&lt;p&gt;for some f(X):&lt;br /&gt;
df = (dfdt + mu * dfdx + 1/2 sig^2 * d^fdx^2)dt + sig * dfdx dW&lt;/p&gt;
</description>
        <pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/2025/02/12/Finance/</link>
        <guid isPermaLink="true">http://localhost:4000/2025/02/12/Finance/</guid>
        
        <category>Quant Finance</category>
        
        
      </item>
    
      <item>
        <title>Thoughts on DeepSeek</title>
        <description>&lt;h2 id=&quot;v3-base&quot;&gt;V3-Base&lt;/h2&gt;
&lt;p&gt;671B decoder-only transformer
Self-supervised pre-training:
No label, train on first half of sentence to predict the second half&lt;/p&gt;

&lt;h2 id=&quot;r1-zero&quot;&gt;R1-Zero&lt;/h2&gt;

&lt;p&gt;Trained on v3-base using reinforcement learning:
Supervised fine tuning (SFT)
Reinforcement Learning from Human Feedback (RLHF)&lt;/p&gt;

&lt;h2 id=&quot;r1&quot;&gt;R1&lt;/h2&gt;

&lt;p&gt;Use R1-zero to come up with good CoT
Use those CoT to fine-tune V3-Base
Then train with SFT to get R1&lt;/p&gt;

&lt;h2 id=&quot;llamaqwen-distilled&quot;&gt;Llama/Qwen Distilled&lt;/h2&gt;

&lt;p&gt;Use R1 to come up with 800k samples, then use those
to train other open-source models: Meta &amp;amp; Qwen&lt;/p&gt;

&lt;h2 id=&quot;other-techniques&quot;&gt;Other techniques&lt;/h2&gt;

&lt;p&gt;MoE system
Multihead latent Attention (MLA)
Distilling using O1
Low-level programming GPU cores
Group Relative Policy Optimization (GRPO)&lt;/p&gt;

</description>
        <pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/2025/02/08/DeepSeek/</link>
        <guid isPermaLink="true">http://localhost:4000/2025/02/08/DeepSeek/</guid>
        
        <category>Deep learning</category>
        
        <category>LLM</category>
        
        
      </item>
    
      <item>
        <title>Data Science Internship</title>
        <description>&lt;h2 id=&quot;data-science-intern-at-natwest-group&quot;&gt;Data Science Intern at Natwest Group&lt;/h2&gt;
&lt;p&gt;Jun - Aug 2024&lt;/p&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;

&lt;p&gt;I was placed into the Data Science team within Natwest Group Solutions, the part of Natwest that focuses on coming up with digital solutions for other parts of the bank. In particular, I was in charge of improving the machine learning classifier for the Suspicious Activity Reports (SAR) which the FinCrime team need to analyze.&lt;/p&gt;

&lt;h3 id=&quot;challenges&quot;&gt;Challenges&lt;/h3&gt;

&lt;p&gt;The SAR are written by different humans, without a set strict format in general. The purpose is to classify each SAR into a category (e.g. Money laundering, gambling, fraud etc), for further analysis. The old classifier used by the FinCrime team is a rule-based model (based on a bunch of if-elses), and can lead to low classication accuracy especially in terms of minority groups. A major challenge for using a machine learning model that can be trained for higher accuracy is the lack of labeled data. While the bank has several thousand SARs per month, human labor are needed to label each SAR with the right category, and we had only 50ish labeled SARs per month.&lt;/p&gt;

&lt;h3 id=&quot;my-approach&quot;&gt;My Approach&lt;/h3&gt;
&lt;p&gt;I developed a novel approach by using LLM to generate synthetic SARs for each category. This way we can scale up the data and allow the training of ML classifiers. To ensure the quality, we employed clustering analysis by looking at the vector embeddings of the original data and the generated data, both fed into the embedding layer of an LLM into a (1546,) vector. We used PCA to find the two most important dimension for plotting the data vectors, computed average consine similarity for both old and new data, and also constructed a cosine-distance based KNN graph. All evidence suggested there isn’t a systematic difference between the old and the new synthetic text data.&lt;/p&gt;

&lt;p&gt;Hence we were able to train a random forest model on top of all the data and achieved a big increase in average classication accuracy across all categories.&lt;/p&gt;

&lt;p&gt;An alternative approach where we directly prompt the LLM to do the classication also worked, though it still suffers from hallucinations and occasionally create categories that didn’t exist.&lt;/p&gt;

&lt;h3 id=&quot;technologies-used&quot;&gt;Technologies Used&lt;/h3&gt;
&lt;p&gt;We used OpenAI API through Azure.&lt;/p&gt;

&lt;p&gt;The coding environment was based on the AWS Sagemaker Studio, and data are stored in the AWS S3 database.&lt;/p&gt;

</description>
        <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/2024/11/01/Natwest/</link>
        <guid isPermaLink="true">http://localhost:4000/2024/11/01/Natwest/</guid>
        
        <category>python</category>
        
        <category>AWS</category>
        
        <category>Internship</category>
        
        
      </item>
    
      <item>
        <title>Machine Learning Internship</title>
        <description>&lt;h2 id=&quot;ml-internship-at-imperials-ai-lab-deepwok&quot;&gt;ML Internship at Imperial’s AI Lab &lt;a href=&quot;https://deepwok.github.io/&quot;&gt;Deepwok&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Apr - Sep 2024&lt;/p&gt;

&lt;h3 id=&quot;project-overview&quot;&gt;Project Overview&lt;/h3&gt;
&lt;p&gt;DNA language models apply techniques from natural language processing (NLP) to model biological sequences, treating DNA as a “language” to capture patterns, structures, and functional elements in genomic data. These models aim to understand and predict biological phenomena by encoding DNA sequences in a format that machine learning models can use.&lt;/p&gt;

&lt;p&gt;Tokenization Methods: In DNA language models, tokenization is the process of breaking down DNA sequences into manageable units, or “tokens,” which represent the genetic information. State-of-the-art DNA models like Hyena used a mere character-level naive tokenizer, simply translating ‘A’, ‘C’, ‘G’, ‘T’ to fixed integers. We were experimenting the adoptation of the 
Byte-Pair Encoding (BPE) method used in GPT3 and GPT4. The idea is to combine frequently occurring character pairs into single tokens iteratively, creating a hierarchy of tokens that balances between single characters and multi-character sequences.&lt;/p&gt;

&lt;h3 id=&quot;contribution&quot;&gt;Contribution&lt;/h3&gt;
&lt;p&gt;As part of the team to develop a BPE-based DNA LLM, my work mostly involves two parts.&lt;/p&gt;

&lt;p&gt;Firstly, I worked on fine-tuning the hyperparameters like the vocab size for BPE, sequence length, context window etc for the DNA LLM. We built our model based on Olmo LLM &lt;a href=&quot;https://huggingface.co/allenai/OLMo-1B&quot;&gt;1B&lt;/a&gt; and &lt;a href=&quot;https://huggingface.co/allenai/OLMo-7B&quot;&gt;7B&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Secondly, I mostly worked on developping a modular evaluation framework that integrates our DNA LLM with downstream tasks (e.g. gene prediction, Protein-DNA interaction prediction) and benchmarks e.g. &lt;a href=&quot;https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks&quot;&gt;Genomic Benchmarks&lt;/a&gt;, enabling automated performance evaluations and comparisons.&lt;/p&gt;

&lt;p&gt;For example, this involves comparing our model’s performance with &lt;a href=&quot;https://github.com/MAGICS-LAB/DNABERT_2&quot;&gt;DNABERT2&lt;/a&gt; and &lt;a href=&quot;https://github.com/HazyResearch/hyena-dna&quot;&gt;Hyena&lt;/a&gt;, both were established State-of-the-Art models on Genomic Benchmarks.&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Sep 2024 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/2024/09/01/Deepwok-Lab-en/</link>
        <guid isPermaLink="true">http://localhost:4000/2024/09/01/Deepwok-Lab-en/</guid>
        
        <category>Pytorch</category>
        
        <category>LLM</category>
        
        <category>Machine Learning</category>
        
        <category>Internship</category>
        
        
      </item>
    
      <item>
        <title>Optiver &amp; Imperial Trading Academy</title>
        <description>&lt;h2 id=&quot;optiver--imperial-trading-academy&quot;&gt;Optiver &amp;amp; Imperial Trading Academy&lt;/h2&gt;
&lt;p&gt;Nov 7 - 29, 2023&lt;/p&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;
&lt;p&gt;This is an 8-session &lt;a href=&quot;https://optiver.com/recruitment-events/imperial-college-london-x-optiver-trading-academy/&quot;&gt;project&lt;/a&gt; that covers both the foundations of options theory and hands-on algorithm development and testing. At the end of the session, I participated with other student traders together in a real-time trading challenge by designing our own Python trading algorithm based on real financial market data.&lt;/p&gt;

&lt;h3 id=&quot;what-i-did&quot;&gt;What I did&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Developed a delta-hedging trading algorithm that autonomously traded options in Optiver’s simulated exchange, Optibook, leveraging the Black-Scholes model for option pricing.&lt;/li&gt;
  &lt;li&gt;Trained an SVM model to dynamically adjust the credit for bid/ask prices based on liquidity, volatility, time to expiry, and historical price movements.&lt;/li&gt;
  &lt;li&gt;Achieved positive PnL of $500,000, ranked in top 20% of participants in the contest with over 50 student traders.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/2023/11/01/optiver/</link>
        <guid isPermaLink="true">http://localhost:4000/2023/11/01/optiver/</guid>
        
        <category>volatility trading</category>
        
        <category>equity option pricing</category>
        
        <category>quantitative research</category>
        
        
      </item>
    
  </channel>
</rss>
